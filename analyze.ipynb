{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the video. \n",
    "`rgb` flag defines whether we would like to use RGB images (`True`) or Grayscale images (`False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_video = 'video/auto.mov' \n",
    "video, fps = load_video(path_to_video, rgb = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames, width, height, fps = get_video_info(path_to_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting an image from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = video[0].copy()\n",
    "show_image_nb(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing layers of Laplacian or Gaussian pyramid.\n",
    "Laplacian pyramid is used in linear-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pyramid(image, pyramid_levels = 4, pyramid = 'laplacian')\n",
    "#Upper image is originally extracted image, lower image is when histogram equalization is applied (for visualisation purposes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing a Region Of Interest (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_coords = {'x1':500, 'x2': 900, 'y1':1300, 'y2':1700} \n",
    "draw_roi_nb(image, square_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFT of the image and ROI(This is optional; if you do not want to show ROI fft, set `square_coords=None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frequencies(video[:-100], fps, square_coords=square_coords)\n",
    "\n",
    "#NOTE: sometimes it's better to pass subarray: video[x:y]. The reason is that for some videos\n",
    "#      the brightness value drops before the video ends so the average of the pixel values looks like the inverse step function, like this: ‾‾‾‾|__\n",
    "#      so it messes up the fft. For instance, this happens for the 'auto' footage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting ROI as separate video (optional)\n",
    "\n",
    "Motion magnification tecniques are memory demanding and the easiest way to go around this issue\n",
    " is to crop the video by choosing the ROI and/or to use grayscale images(`rgb=False`) when we load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_roi_video(video, 'video_results/cropped_video.avi', fps, square_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical flow\n",
    "\n",
    "Dense Optical Flow is calculated, which means that the flow is calculated for every pixel in the image.\n",
    "ROI must be selected over which we *average* the flow! We can select the ROI with the help of `draw_roi_nb` function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input = \"video_results/auto_linear_based_10-20Hz_3Levels_20Amp_butterFilter.avi\"\n",
    "video, fps = load_video(video_input, rgb = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the ROI over which we average the flow\n",
    "\n",
    "NOTE: By selecting the smaller ROI, we have more precise calculation of the motion vector. This is important if we want to extract the exact motion vector of some small part of the footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_coords = {'x1':290, 'x2': 310, 'y1':510, 'y2':530}\n",
    "draw_roi_nb(video[0].copy(), square_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`base_point` is the base of the vector we draw, it is usually placed in the middle of the ROI.\n",
    "`amplitude` is the number we multiply the length of the vector for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_point = (500, 300)\n",
    "amplitude = 30\n",
    "\n",
    "show_optical_flow_roi(video_input, base_point, square_coords, amplitude)\n",
    "# NOTE: press 'q' to exit!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2ff6f068e98f674f782e276b12311dce195d6734b4b6e87366658738dfb5310"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
